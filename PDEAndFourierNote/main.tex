\documentclass{article}

\usepackage[a4paper]{geometry}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}

\usepackage{multicol}

% See https://tex.stackexchange.com/a/39755
% Simulated package file
\begin{filecontents}{envcode.sty}
    \newcommand\NewEnvCode[2]{%
        \expandafter\def\csname code@#1\endcsname{#2}%
        \expandafter\def\csname change@code@#1\endcsname{%
            \expandafter\let\expandafter\Code\csname code@#1\endcsname
        }%
    }
    
    \newcommand\MakeDefault{%
        \expandafter\let\expandafter\code@@default\csname code@\@currenvir\endcsname
    }
    
    \newcommand\RunEnvCode{%
        \let\Code=\code@@default
        \csname change@code@\@currenvir\endcsname
        \Code
    }
    
    \AtBeginDocument{\MakeDefault}
\end{filecontents}
\usepackage{envcode}

\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{question}{Question}[section]
\newtheorem{example}{Example}[section]

\NewEnvCode{document}{default code}
\NewEnvCode{theorem}{ theorem }
\NewEnvCode{lemma}{ lemma }
\NewEnvCode{corollary}{ corollary }
\NewEnvCode{proposition}{ proposition }
\NewEnvCode{definition}{ definition }
\NewEnvCode{question}{ question }
\NewEnvCode{example}{ example }

\begin{document}

\begin{enumerate}
    \item Orders of ODE
          \begin{definition}
              An ODE is said to be of order $n$ if the highest order
              derivative of the unknown function
              that appears in the ODE is of order $n$.
          \end{definition}
    \item Degree of ODE
          \begin{definition}
              An ODE is said to be of degree $n$ if the highest power
              of the highest order derivative of the unknown function
              that appears in the ODE is $n$.
          \end{definition}
          \begin{example}
              The ODE $y'' + y = 0$ is of order $2$ and degree $1$.
          \end{example}
    \item Linear ODE
          \begin{definition}
              An ODE is said to be linear if it can be written in the form
              \begin{equation}
                  a_n(x) y^{(n)} + a_{n-1}(x) y^{(n-1)} + \cdots + a_1(x) y' + a_0(x) y = f(x),
              \end{equation}
              where $a_i(x)$ are functions of $x$ and $f(x)$ is a function of $x$.
          \end{definition}
    \item Homogeneous ODE
          \begin{definition}
              An ODE is said to be homogeneous
              if the term that does not involve the unknown function
              is zero.
          \end{definition}
          \begin{example}
              The ODE $y'' + y = 0$ is homogeneous.

              The ODE $y'' + y = x$ is not homogeneous.
          \end{example}
    \item The superposition principle
          \begin{theorem}
              If $y_1(x)$ and $y_2(x)$ are solutions of a homogeneous linear ODE,
              then $c_1 y_1(x) + c_2 y_2(x)$ is also a solution of the ODE,
              where $c_1$ and $c_2$ are constants.
          \end{theorem}
    \item Series solution of ODE
          \begin{theorem}
              It is possible to construct a series solution for most ODEs.

              For ODE:
              \begin{equation}
                  P(x) y'' + Q(x) y' + R(x) y = 0
              \end{equation}

              If we are interested in finding a solution around $x = x_0$,
              we can assume the solution to be of the form:
              \begin{equation}
                  y(x) = \sum_{n=0}^{\infty} a_n (x - x_0)^n
              \end{equation}

              Then expanding $P$, $Q$, and $R$ in Taylor series around $x = x_0$,
              we can substitute the series solution into the ODE,
              and solve for the coefficients $a_n$.
          \end{theorem}
          \begin{example}
              Find the series solution of the ODE
              \begin{equation}
                  (1+x^2) y'' + x y' - y = 0
              \end{equation}
              about $x = 0$.

              We assume the solution to be of the form:
              \begin{equation}
                  y(x) = \sum_{n=0}^{\infty} a_n x^n
              \end{equation}

              Substituting the series solution into the ODE,
              we have:
              \begin{eqnarray}
                  (1+x^2) \sum_{n=0}^{\infty} a_n n (n-1) x^{n-2}
                  + x \sum_{n=0}^{\infty} a_n n x^{n-1}
                  - \sum_{n=0}^{\infty} a_n x^n = 0 \\
                  \sum_{n=0}^{\infty} a_n n (n-1) x^n
                  + \sum_{n=0}^{\infty} a_n n x^n
                  - \sum_{n=0}^{\infty} a_n x^n
                  + \sum_{n=0}^{\infty} a_n n (n-1) x^{n-2}
                  = 0 \\
                  \sum_{n=0}^{\infty} a_n n (n-1) x^n
                  + \sum_{n=0}^{\infty} a_n n x^n
                  - \sum_{n=0}^{\infty} a_n x^n
                  + \sum_{n=0}^{\infty} a_{n+2} (n+2) (n+1) x^{n}
                  = 0 \\
                  \sum_{n=0}^{\infty} \left(
                  \left(
                  n (n-1) + n - 1
                  \right)
                  a_n
                  + (n+2) (n+1) a_{n+2}
                  \right) x^n
                  = 0
              \end{eqnarray}

              Since the series must be zero for all $x$,
              the coefficients of $x^n$ must be zero for all $n$.
              Therefore, we have:
              \begin{eqnarray}
                  \left(
                  (n+1)(n-1)
                  \right)
                  a_n
                  + (n+2) (n+1) a_{n+2}
                  &=& 0, \quad n \geq 0 \\
                  a_{n+2} &=& -\frac{(n+1)(n-1)}{(n+2)(n+1)} a_n \\
                  a_{n+2} &=& -\frac{n-1}{n+2} a_n
              \end{eqnarray}

              And it is clear that the general solution depends on $a_0$ and $a_1$,
              and has a degeneracy of $2$.
          \end{example}
    \item Ordinary points and singular points
          \begin{definition}
              Given an ODE of the form:
              \begin{equation}
                  P(x) y'' + Q(x) y' + R(x) y = 0
              \end{equation}

              A point $x = x_0$ is said to be an ordinary point if
              $Q(x)/P(x)$, and $R(x)/P(x)$ are analytic at $x = x_0$.

              Otherwise, $x = x_0$ is said to be a singular point.

              Trying to find a series solution around an ordinary point
              will result in a solution that has a degeneracy of $2$.
          \end{definition}
    \item Regular singular points
          \begin{definition}
              Given an ODE of the form:
              \begin{equation}
                  P(x) y'' + Q(x) y' + R(x) y = 0
              \end{equation}

              A singular point $x = x_0$ is said to be a regular singular point if
              $(x - x_0) Q(x)/P(x)$, and $(x - x_0)^2 R(x)/P(x)$ are analytic at $x = x_0$.
              Otherwise, it is an irregular singular point.

              Finding a solution around a regular singular point will need special treatment.
          \end{definition}
    \item Euler Equation
          \begin{definition}
              An ODE of the form:
              \begin{equation}
                  x^2 y'' + a x y' + b y = 0
              \end{equation}
              is called an Euler equation.

              If the quadraric eqation:
              \begin{equation}
                  m^2 + (a-1) m + b = 0
              \end{equation}
              has two distinct roots $m_1$ and $m_2$,
              then the general solution of the Euler equation is:
              \begin{equation}
                  y(x) = c_1 x^{m_1} + c_2 x^{m_2}
              \end{equation}

              If the quadratic equation has a single root $m$,
              then the general solution of the Euler equation is:
              \begin{equation}
                  y(x) = c_1 x^m + c_2 x^m \ln x
              \end{equation}
          \end{definition}
    \item Frobenius method
          \begin{definition}
              The Frobenius method is a method to find the series solution of ODEs around regular singular points.

              Given an ODE of the form:
              \begin{equation}
                  P(x) y'' + Q(x) y' + R(x) y = 0
              \end{equation}

              Assume the solution to be of the form:
              \begin{equation}
                  y(x) = \sum_{n=0}^{\infty} a_n (x - x_0)^{n+m}
              \end{equation}

              Where $m$ is the root of the indicial equation:
              \begin{equation}
                  m^2 + (\lim_{x\rightarrow x_0}\frac{xQ}{P}-1) m
                  + \lim_{x\rightarrow x_0}\frac{x^2R}{P} = 0
              \end{equation}

              Substituting the series solution into the ODE,
              we can solve for the coefficients $a_n$.

              If the indical equation has two same roots,
              then the general solution will be in the form
              \begin{equation}
                  y(x) = \log(x) \sum_{n=0}^{\infty} a_n (x - x_0)^{n+m}
                  + \sum_{n=0}^{\infty} b_n (x - x_0)^{n+m}
              \end{equation}

              If given $m_{1} > m_{2} $ and $m_{1} - m_{2} \in \mathbb{Z}$,
              then the general solution will be in the form
              \begin{equation}
                  y(x) = \log(x) \sum_{n=0}^{\infty} a_n (x - x_0)^{n+m_{1}}
                  + \sum_{n=0}^{\infty} b_n (x - x_0)^{n+m_{2}}
              \end{equation}

              The Frobenius method is used when we try to find the series solution
              around a regular singular point.
          \end{definition}
          \begin{example}
              Find a series solution of the ODE:
              \begin{equation}
                  2x y'' + (3-2x) y' + y = 0
              \end{equation}

              It is easy to see that $x = 0$ is a regular singular point.

              Solving the indicial equation:
              \begin{equation}
                  m^2 + (\frac{3}{2}-1) m = 0
              \end{equation}
              we have $m = 0$ or $m = 1$.

              Therefore, assume the general solution to be of the form:
              \begin{equation}
                  y(x) = \sum_{n=0}^{\infty} a_n x^{n+m}
              \end{equation}

              Substituting the series solution into the ODE,
              we have:
              \begin{eqnarray}
                  2x \sum_{n=0}^{\infty} a_n (n+m)(n+m-1) x^{n+m-2} && \\
                  + (3-2x) \sum_{n=0}^{\infty} a_n (n+m) x^{n+m-1}
                  + \sum_{n=0}^{\infty} a_n x^{n+m}
                  &=& 0 \\
                  2 \sum_{n=0}^{\infty} a_n (n+m)(n+m-1) x^{n+m-1} && \\
                  + 3 \sum_{n=0}^{\infty} a_n (n+m) x^{n+m-1} && \\
                  - 2 \sum_{n=0}^{\infty} a_n (n+m) x^{n+m}
                  + \sum_{n=0}^{\infty} a_n x^{n+m}
                  &=& 0 \\
                  2a_{0} m (m-1) x^{m-1} + 3a_{0} m x^{m-1} && \\
                  + 2 \sum_{n=0}^{\infty} \left(
                  \left(
                  (n + 1 + m)(2(n + m) + 3)
                  \right) a_{n + 1}
                  + \left(
                  1 - 2(n + m)
                  \right) a_{n} \right) x^{n+m}
                  &=& 0
              \end{eqnarray}

              $2a_{0} m (m-1) x^{m-1} + 3a_{0} m x^{m-1}$ is automatically satisfied,
              as it is the same with the indicial equation.

              Therefore, we have:
              \begin{eqnarray}
                  \left(
                  (n + 1 + m)(2(n + m) + 3)
                  \right) a_{n + 1}
                  + \left(
                  1 - 2(n + m)
                  \right) a_{n} &=& 0
              \end{eqnarray}

              As $m$ has two values, the general solution will depend on $a_0$ and $m$,
              and has a degeneracy of $2$.
          \end{example}
    \item Legendre Equation
          \begin{definition}
              The Legendre equation is given by:
              and is given by:
              \begin{equation}
                  (1-x^2) y'' - 2x y' + \alpha(\alpha+1) y = 0
                  \label{eq:legendre}
              \end{equation}

              As the Legendre equation has an ordinary point at $x = 0$,
              we can solve this equation for two linearly independent series solutions:
              $y_{0,\alpha}(x)$, and $y_{1,\alpha}(x)$.

              If $\alpha$ is not a integer, then both $y_{0,\alpha}(x)$, and $y_{1,\alpha}(x)$
              is an infinite series with a radius of convergence $1$.
          \end{definition}
    \item Legendre Polynomial
          \begin{definition}
              If $\alpha$ in Equation \ref{eq:legendre} is an integer,
              then the series solution to Equation \ref{eq:legendre} is a polynomial,
              which is often known as the Legendre polynomial.
          \end{definition}
          \begin{theorem} [Orthogonality of Legendre Polynomials]
              The Legendre polynomials are orthogonal on the interval $[-1, 1]$,
              that is:
              \begin{equation}
                  \int_{-1}^{1} P_{n}(x) P_{m}(x) \, dx = \frac{2\delta_{nm}}{2n+1}
              \end{equation}
          \end{theorem}
          \begin{theorem}[Negative index Legendre Polynomial]
              As the equation \ref{eq:legendre} is invariant under $\alpha \rightarrow -\alpha - 1$,
              \begin{equation}
                  P_{n} (x) = P_{-n-1}(x)
              \end{equation}
          \end{theorem}
    \item Bessel Equation
          \begin{definition}
              The Bessel equation is given by:
              \begin{equation}
                  x^2 y'' + x y' + (x^2 - \nu ^2) y = 0
              \end{equation}

              As the Bessel equation has a regular singular point at $x = 0$,
              we can solve this equation for two linearly independent series solutions.
          \end{definition}
    \item Fourier Series
          \begin{definition}
              The Fourier series of a function $f(x)$ is given by:
              \begin{equation}
                  f(x) = \frac{a_0}{2} + \sum_{n=1}^{\infty} a_n \cos \left( \frac{n \pi x}{L} \right) + b_n \sin \left( \frac{n \pi x}{L} \right)
              \end{equation}
              where
              \begin{eqnarray}
                  a_n &=& \frac{1}{L} \int_{-L}^{L} f(x) \cos \left( \frac{n \pi x}{L} \right) \, dx \\
                  b_n &=& \frac{1}{L} \int_{-L}^{L} f(x) \sin \left( \frac{n \pi x}{L} \right) \, dx
              \end{eqnarray}
          \end{definition}
    \item Trigonometric Integration Formula
          \begin{definition}
              The trigonometric integration formula is given by:
              \begin{eqnarray}
                  \int_{-\pi}^{\pi} \cos(mx)\cos(nx) dx &=& \pi \delta_{mn} \\
                  \int_{-\pi}^{\pi} \sin(mx)\sin(nx) dx &=& \pi \delta_{mn} \\
                  \int_{-\pi}^{\pi} \cos(mx)\sin(nx) dx &=& 0
              \end{eqnarray}
          \end{definition}
    \item Fourier Convergence Theorem
          \begin{theorem}
              If $f(x)$ is piecewise continuous on $[-L, L]$,
              then the Fourier series of $f(x)$ converges to $f(x)$ at all points where $f(x)$ is continuous,
              and converges to the average of the left and right limits of $f(x)$ at points where $f(x)$ is discontinuous.

              If the edge of the discontinuity is at $x = a$,
              then there will be the Gibbs phenomenon at $x = a$.
          \end{theorem}
    \item Gibbs Phenomenon
          \begin{definition}
              The Gibbs phenomenon is the overshoot of the Fourier series at the edge of a discontinuity.
          \end{definition}
    \item Use Fourier Series to Solve ODE with Periodic Forcing Term
          \begin{example}
              Solve the ODE:
              \begin{equation}
                  y'' + \omega^2 y = F(x)
              \end{equation}

              Where $F$ is a $2 \pi$ periodic function with definition $F(x)$ on $[- \pi, \pi]$:
              \begin{equation}
                  F(x) = \begin{cases}
                      \pi + t, & -\pi \leq x < 0 \\
                      \pi - t, & 0 \leq x < \pi
                  \end{cases}
              \end{equation}

              We first derive the Fourier series of $F(x)$:
              \begin{eqnarray}
                  a_{n} &=& \int_{-\pi}^{\pi} F(x) \cos(nx) \, dx \\
                  &=& 2 \int_{0}^{\pi} (\pi - t) \cos(nx) \, dx \\
                  &=& 2\left(
                  \frac{1}{n}(\pi - t) \sin(nx) \mid_{0}^{\pi}
                  +\int_{0}^{\pi} \frac{1}{n}\sin(nx)
                  \right) \\
                  &=& 2\left(
                  +\frac{1}{n^2}(-\cos(nx)) \mid_{0}^{\pi}
                  \right) \\
                  &=& -\frac{2}{n^2}\left(
                  \cos(n\pi) - 1
                  \right) \\
                  &=& -\frac{2}{n^2}\left(
                  (-1)^n - 1
                  \right) \\
                  b_n &=& \int_{-\pi}^{\pi} F(x) \sin(nx) \, dx \\
                  &=& 0 \\
                  a_{0} &=& \int_{-\pi}^{\pi} F(x) \cos(nx) \, dx \\
                  &=& 2 \int_{0}^{\pi} (\pi - t) \, dx \\
                  &=& \pi^2
              \end{eqnarray}

              For the particular solution, we assume the solution to be of the form:
              \begin{equation}
                  y_p(x) = \frac{A_{0}}{2} + \sum_{n=1}^{\infty}\left(
                  A_{n} \cos(nx) + B_{n} \sin(nx)
                  \right)
              \end{equation}

              Then we have:
              \begin{eqnarray}
                  && \begin{cases}
                      \omega^2 \frac{A_{0}}{2} = \frac{a_{0}}{2} \\
                      -A_{n} n^2 + \omega^2 A_{n} = a_{n}        \\
                      -B_{n} n^2 + \omega^2 B_{n} = b_{n} = 0
                  \end{cases}
                  \\
                  && \begin{cases}
                      A_{0} = \frac{a_{0}}{\omega^2}       \\
                      A_{n} = \frac{a_{n}}{n^2 - \omega^2} \\
                      B_{n} = 0
                  \end{cases}
              \end{eqnarray}

              The general solution is then:
              \begin{equation}
                  y(x) = c_1 \cos(\omega x) + c_2 \sin(\omega x) + y_p(x)
              \end{equation}
          \end{example}
    \item Laplace Equation
          \begin{definition}
              The Laplace equation is given by:
              \begin{equation}
                  \nabla ^2 \phi = 0
              \end{equation}
          \end{definition}
    \item Wave Equation
          \begin{definition}
              The wave equation is given by:
              \begin{equation}
                  \frac{\partial^2 u}{\partial t^2} = c^2 \frac{\partial^2 u}{\partial x^2}
              \end{equation}
          \end{definition}
    \item Heat Equation
          \begin{definition}
              The heat equation is given by:
              \begin{equation}
                  \frac{\partial u}{\partial t} = k \frac{\partial^2 u}{\partial x^2}
              \end{equation}
          \end{definition}
    \item Using Change of Variable to Solve Wave Equation
          \begin{proof}
              Give the wave equation:
              \begin{equation}
                  \frac{\partial^2 u}{\partial t^2} = c^2 \frac{\partial^2 u}{\partial x^2}
              \end{equation}

              We can use the change of variable:
              \begin{eqnarray}
                  2\xi &=& x - ct \\
                  2\eta &=& x + ct
              \end{eqnarray}

              Then we have:
              \begin{eqnarray}
                  \frac{\partial}{\partial x} &=& \frac{\partial}{\partial \xi} + c \frac{\partial}{\partial \eta} \\
                  \frac{\partial}{\partial t} &=& -c \frac{\partial}{\partial \xi} + c \frac{\partial}{\partial \eta}
              \end{eqnarray}

              Substituting the change of variable into the wave equation,
              we have:
              \begin{eqnarray}
                  \frac{\partial^2 u}{\partial t^2} &=& c^2 \frac{\partial^2 u}{\partial x^2} \\
                  \left(
                  -c \frac{\partial}{\partial \xi} + c \frac{\partial}{\partial \eta}
                  \right)
                  \left(
                  -c \frac{\partial}{\partial \xi} + c \frac{\partial}{\partial \eta}
                  \right) u
                  &=& c^2 \left(
                  \frac{\partial}{\partial \xi} + c \frac{\partial}{\partial \eta}
                  \right)
                  \left(
                  \frac{\partial}{\partial \xi} + c \frac{\partial}{\partial \eta}
                  \right) u \\
                  \left(
                  c^2 \frac{\partial^2 u}{\partial \xi^2}
                  - 2c^2 \frac{\partial^2 u}{\partial \xi \partial \eta}
                  + c^2 \frac{\partial^2 u}{\partial \eta^2}
                  \right)
                  &=& c^2 \left(
                  \frac{\partial^2 u}{\partial \xi^2}
                  + 2c \frac{\partial^2 u}{\partial \xi \partial \eta}
                  + c^2 \frac{\partial^2 u}{\partial \eta^2}
                  \right) \\
                  \frac{\partial^2 u}{\partial \xi \partial \eta} &=& 0
              \end{eqnarray}

              Integrating the equation, we have:
              \begin{equation}
                  u = f(\xi) + g(\eta)
              \end{equation}
              which is the general solution of the wave equation.
          \end{proof}
    \item Solving Spherical Laplace Equation
          \begin{proof}
              We are interested in solving the Laplace equation in spherical coordinates,
              with the assumption that the solution is independent of $\phi$.

              The general solution is then:
              \begin{equation}
                  \phi(r, \theta) = \sum_{l=0}^{\infty}
                  A_{l} r^l
                  P_{l}(\cos \theta)
                  + \sum_{l=-1}^{-\infty}
                  B_{l} r^{l} P_{l}(\cos \theta)
              \end{equation}
          \end{proof}
    \item Fourier Transform
          \begin{definition}
              The Fourier transform of a function $f(x)$ is given by:
              \begin{equation}
                  \mathcal{F}(f) =  F(k) = \int_{-\infty}^{\infty} e^{ikx} f(x)  \, dx
              \end{equation}

              The inverse Fourier transform of a function $F(k)$ is given by:
              \begin{equation}
                  \mathcal{F}^{-1}(F) = f(x) = \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{-ikx} F(k) \, dk
              \end{equation}
          \end{definition}
    \item Properties of Fourier Transform
          \begin{theorem}
              The Fourier transform is linear, that is:
              \begin{equation}
                  \mathcal{F}(a f + b g) = a \mathcal{F}(f) + b \mathcal{F}(g)
              \end{equation}

              The Fourier transform of the derivative of a function is given by:
              \begin{equation}
                  \mathcal{F}(\frac{df}{dx}) = -ik \mathcal{F}(f)
              \end{equation}

              The Fourier transform of the convolution of two functions is given by:
              \begin{equation}
                  \mathcal{F}(f * g) = \mathcal{F}(f) \mathcal{F}(g)
              \end{equation}

              Double Fourier transform is the original function with a negative sign and a constant:
              \begin{equation}
                  \mathcal{F}(\mathcal{F}(f(x))) = 2\pi f(-x)
              \end{equation}
          \end{theorem}
    \item Laplace Transform
          \begin{definition}
              The Laplace transform of a function $f(t)$ is given by:
              \begin{equation}
                  \mathcal{L}(f) =  F(s) = \int_{0}^{\infty} e^{-st} f(t)  \, dt
              \end{equation}

              The inverse Laplace transform needs knowledge of complex analysis,
              which is not covered in this note.
          \end{definition}
    \item Properties of Laplace Transform
          \begin{definition}
              The Laplace transform is linear, that is:
              \begin{equation}
                  \mathcal{L}(\alpha f + \beta g) =
                  \alpha \mathcal{f} + \beta \mathcal{g}
              \end{equation}

              Laplace transform of indefinite integral is given by:
              \begin{eqnarray}
                  \mathcal{L}(\int_{0}^{t}f(x) dx) &=&
                  \int_{0}^{\infty} e^{-st} \int_{0}^{t} f(x) dx dt \\
                  &=& \left[-\frac{1}{s}e^{-st} \int_{0}^{t} f(x) dx \right]_{0}^{\infty}
                  + \frac{1}{s} \int_{0}^{\infty} e^{-st} f(t) dt \\
                  &=& \frac{1}{s} \mathcal{L}(f)
              \end{eqnarray}
          \end{definition}
\end{enumerate}

\end{document}